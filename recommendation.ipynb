{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "import zipfile\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise import accuracy\n",
    "import random\n",
    "from random import randint\n",
    "import re\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into an array of strings\n",
    "def read_data():\n",
    "    with open('./new_data.data') as f:\n",
    "        all_lines = f.readlines()\n",
    "\n",
    "    # Prepare the data to be used in Surprise\n",
    "    reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "    data = Dataset.load_from_file('./new_data.data', reader=reader)\n",
    "    \n",
    "    return all_lines, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lines, data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    data = [ x.replace('\\t', ', ').replace('\\n', '') for x in data ]\n",
    "\n",
    "    df = pd.DataFrame([sub.split(\",\") for sub in data])\n",
    "    df.rename(columns={0:'userID', 1:'movieID', 2:'rating', 3: 'timestamp'}, \n",
    "                         inplace=True)\n",
    "    df = df.drop(columns=['timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_content(data):\n",
    "    r_unwanted = re.compile(\"[\\n\\t\\r]\")\n",
    "    return r_unwanted.sub(\",\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = create_dataframe(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataframe(data):\n",
    "#     df_data = pd.DataFrame(data)\n",
    "\n",
    "#     df_data[0] = df_data[0].apply(strip_content)\n",
    "\n",
    "#     foo = lambda x: pd.Series([i for i in (x.split(','))])\n",
    "\n",
    "#     df_final = df_data[0].apply(foo)\n",
    "\n",
    "#     df_final.rename(columns={0:'userID', 1:'movieID', 2:'rating', 3: 'timestamp'}, \n",
    "#                      inplace=True)\n",
    "\n",
    "#     df_final = df_final.drop(columns=[4])\n",
    "    \n",
    "#     return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\"],\n",
    "#     \"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [False, True],\n",
    "# }\n",
    "\n",
    "# param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "# gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Grid search for best params </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"n_epochs\": [5, 10],\n",
    "#     \"lr_all\": [0.002, 0.005],\n",
    "#     \"reg_all\": [0.1, 0.2, 0.4, 0.6]\n",
    "# }\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> SVD algo chosen, with best params obtained from GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create train and test set, apply predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_predict_train_test(data):\n",
    "    # sample random trainset and testset\n",
    "    # test set is made of 25% of the ratings.\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "    # We'll use the famous SVD algorithm.\n",
    "    algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)\n",
    "\n",
    "    # Train the algorithm on the trainset, and predict ratings for the testset\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    return accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Training Time\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def training_time(data):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    algo.fit(trainset)\n",
    "\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_time(data_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Predict scores for all users for all movies. Test the speed of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores(data):\n",
    "    # Build Training set. Needed to fit to create model.\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    # Create empty list to store predictions\n",
    "    ratings = []\n",
    "    \n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings.append(prediction)\n",
    "            \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Time to predict all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "\n",
    "# start = timeit.default_timer()\n",
    "\n",
    "\n",
    "# ratings = predict_scores(data_other)\n",
    "    \n",
    "# stop = timeit.default_timer()\n",
    "\n",
    "# print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores_dict(data):\n",
    "    # Build Training set. Needed to fit to create model.\n",
    "    print(\"build trainingset\")\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    print(\"training algo\")\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "    \n",
    "    # Create empty list to store predictions\n",
    "    ratings = {}\n",
    "    ratings_list = []\n",
    "    \n",
    "    print(\"start prediction\")\n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings['userID'] = int(user_id)\n",
    "            ratings['movieID'] = int(item_id)\n",
    "            ratings['rating'] = prediction\n",
    "            \n",
    "            ratings_list.append(ratings)\n",
    "            \n",
    "            ratings = {}\n",
    "            \n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "\n",
    "# start = timeit.default_timer()\n",
    "\n",
    "# predicted_scores_dict =  predict_scores_dict(data)\n",
    "    \n",
    "# stop = timeit.default_timer()\n",
    "\n",
    "# print('Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prediction = pd.DataFrame(predicted_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_prediction = []\n",
    "# complete_prediction = pd.DataFrame(complete_prÂ²ediction)\n",
    "# for i in range(0, len(predicted_scores_dict), 10000000):\n",
    "#     print(\"appending\",i, i+10000000)\n",
    "#     complete_prediction = complete_prediction.append(predicted_scores_dict[i:i+10000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data):\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    data_list = []\n",
    "    # Create new movies (168200 in total)\n",
    "    for movie in range(item_ids[-1]+1, item_ids[-1]*100):\n",
    "        # For every movie, there will be 100 users rating the movie\n",
    "        user_generated = [randint(0, user_ids[-1]) for p in range(0, 100)]\n",
    "        for user in user_generated:\n",
    "            # Create a random generated score for the movies\n",
    "            new_data = str(user)+'\\t'+str(movie)+'\\t'+str(random.randint(1,5))+'\\t'+'NaN\\n'\n",
    "\n",
    "            data_list.append(new_data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_newest = create_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new data (as a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = []\n",
    "\n",
    "# new_data.extend(all_lines)\n",
    "# new_data.extend(data_newest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check difference in sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_newest)/len(all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Search Function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dups(userID, df_final, predicted_scores_df):\n",
    "\n",
    "    df_user0_predicted = predicted_scores_df[predicted_scores_df['userID'] == userID]\n",
    "    # df_user0_predicted.sort_values('rating', ascending=False)\n",
    "    df_user0_predicted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_user0_original = df_final[df_final['userID'] == userID]\n",
    "    df_user0_original.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfs_dictionary = {'DF1':df_user0_predicted,'DF2':df_user0_original}\n",
    "    df3=pd.concat(dfs_dictionary)\n",
    "    df3=df3.drop_duplicates(subset=['userID', 'movieID'],keep=False)\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_movies_for_user(userID, amount_of_movies, df_final, predicted_scores_df):\n",
    "    ascending_ratings = drop_dups(userID, df_final, predicted_scores_df).sort_values('rating', ascending=False)\n",
    "    \n",
    "    return ascending_ratings[0:amount_of_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_dataframe(predicted_scores_dict):\n",
    "    complete_prediction = []\n",
    "    complete_prediction = pd.DataFrame(complete_prediction)\n",
    "    for i in range(0, len(predicted_scores_dict), 10000000):\n",
    "        print(\"appending\",i, i+10000000)\n",
    "        complete_prediction = complete_prediction.append(predicted_scores_dict[i:i+10000000])\n",
    "        \n",
    "    return complete_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    all_lines, data = read_data()\n",
    "    \n",
    "    print(\"create df_final\")\n",
    "    df_final = create_dataframe(all_lines).astype('int')\n",
    "    \n",
    "    print(\"predict scores\")\n",
    "    predicted_scores_dict =  predict_scores_dict(data)\n",
    "    \n",
    "    df_predicted_scores = insert_into_dataframe(predicted_scores_dict)\n",
    "#     df_predicted_scores = pd.DataFrame(predicted_scores_dict)\n",
    "    \n",
    "    return df_final, df_predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final, df_predicted_scores = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create df_final\n",
      "predict scores\n",
      "build trainingset\n",
      "training algo\n",
      "start prediction\n",
      "appending 0 10000000\n"
     ]
    }
   ],
   "source": [
    "df_final2, df_predicted_scores2 = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.012946999999257969\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "best_movies = best_movies_for_user(1,10,df_final2, df_predicted_scores2)    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>852786</td>\n",
       "      <td>507</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852824</td>\n",
       "      <td>507</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852838</td>\n",
       "      <td>507</td>\n",
       "      <td>64</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852888</td>\n",
       "      <td>507</td>\n",
       "      <td>114</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852943</td>\n",
       "      <td>507</td>\n",
       "      <td>169</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852952</td>\n",
       "      <td>507</td>\n",
       "      <td>178</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853092</td>\n",
       "      <td>507</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853182</td>\n",
       "      <td>507</td>\n",
       "      <td>408</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853257</td>\n",
       "      <td>507</td>\n",
       "      <td>483</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853377</td>\n",
       "      <td>507</td>\n",
       "      <td>603</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157228</td>\n",
       "      <td>688</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157280</td>\n",
       "      <td>688</td>\n",
       "      <td>64</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157330</td>\n",
       "      <td>688</td>\n",
       "      <td>114</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157385</td>\n",
       "      <td>688</td>\n",
       "      <td>169</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157534</td>\n",
       "      <td>688</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157624</td>\n",
       "      <td>688</td>\n",
       "      <td>408</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157699</td>\n",
       "      <td>688</td>\n",
       "      <td>483</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525743</td>\n",
       "      <td>907</td>\n",
       "      <td>169</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525892</td>\n",
       "      <td>907</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525982</td>\n",
       "      <td>907</td>\n",
       "      <td>408</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  movieID  rating\n",
       "852786      507       12     5.0\n",
       "852824      507       50     5.0\n",
       "852838      507       64     5.0\n",
       "852888      507      114     5.0\n",
       "852943      507      169     5.0\n",
       "852952      507      178     5.0\n",
       "853092      507      318     5.0\n",
       "853182      507      408     5.0\n",
       "853257      507      483     5.0\n",
       "853377      507      603     5.0\n",
       "1157228     688       12     5.0\n",
       "1157280     688       64     5.0\n",
       "1157330     688      114     5.0\n",
       "1157385     688      169     5.0\n",
       "1157534     688      318     5.0\n",
       "1157624     688      408     5.0\n",
       "1157699     688      483     5.0\n",
       "1525743     907      169     5.0\n",
       "1525892     907      318     5.0\n",
       "1525982     907      408     5.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted_scores2[df_predicted_scores2['rating']>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
