{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "import zipfile\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise import accuracy\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into an array of strings\n",
    "with open('./ml-100k/u.data') as f:\n",
    "    all_lines = f.readlines()\n",
    "\n",
    "# Prepare the data to be used in Surprise\n",
    "reader_other = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data_other = Dataset.load_from_file('./ml-100k/u.data', reader=reader_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_content(data):\n",
    "    return r_unwanted.sub(\", \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    df_data = pd.DataFrame(data)\n",
    "\n",
    "    df_data[0] = df_data[0].apply(strip_content)\n",
    "\n",
    "    foo = lambda x: pd.Series([i for i in (x.split(','))])\n",
    "\n",
    "    df_final = df_data[0].apply(foo)\n",
    "\n",
    "    df_final.rename(columns={0:'userID', 1:'movieID', 2:'rating', 3: 'timestamp'}, \n",
    "                     inplace=True)\n",
    "\n",
    "    df_final = df_final.drop(columns=[4])\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = create_dataframe(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\"],\n",
    "#     \"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [False, True],\n",
    "# }\n",
    "\n",
    "# param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "# gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Grid search for best params </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"n_epochs\": [5, 10],\n",
    "#     \"lr_all\": [0.002, 0.005],\n",
    "#     \"reg_all\": [0.4, 0.6]\n",
    "# }\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> SVD algo chosen, with best params obtained from GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9558  0.9624  0.9699  0.9590  0.9600  0.9614  0.0047  \n",
      "MAE (testset)     0.7654  0.7715  0.7773  0.7686  0.7693  0.7704  0.0040  \n",
      "Fit time          4.64    3.77    4.87    4.72    4.45    4.49    0.39    \n",
      "Test time         0.18    0.24    0.25    0.34    0.16    0.24    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.95582906, 0.96236882, 0.96985865, 0.95903964, 0.95997643]),\n",
       " 'test_mae': array([0.76539136, 0.77151636, 0.77731087, 0.76855886, 0.7693242 ]),\n",
       " 'fit_time': (4.642159700393677,\n",
       "  3.7680797576904297,\n",
       "  4.870599031448364,\n",
       "  4.724268674850464,\n",
       "  4.45410943031311),\n",
       " 'test_time': (0.17978334426879883,\n",
       "  0.2381908893585205,\n",
       "  0.2549247741699219,\n",
       "  0.3442046642303467,\n",
       "  0.1583545207977295)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create train and test set, apply predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_predict_train_test(data):\n",
    "    # sample random trainset and testset\n",
    "    # test set is made of 25% of the ratings.\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "    # We'll use the famous SVD algorithm.\n",
    "    algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)\n",
    "\n",
    "    # Train the algorithm on the trainset, and predict ratings for the testset\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    return accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Training Time\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "def training_time(data):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    algo.fit(trainset)\n",
    "\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2.2829717\n"
     ]
    }
   ],
   "source": [
    "training_time(data_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Predict scores for all users for all movies. Test the speed of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores(data):\n",
    "    # Build Training set. Needed to fit to create model.\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    # Create empty list to store predictions\n",
    "    ratings = []\n",
    "    \n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings.append(prediction)\n",
    "            \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Time to predict all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  11.7596633\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "ratings = predict_scores(data_other)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores_df(data, df):\n",
    "    # Build Training set. Needed to fit to create model.\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    # Create empty list to store predictions\n",
    "    ratings = {}\n",
    "    ratings_list = []\n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings['userID'] = str(user_id)\n",
    "            ratings['movieID'] = str(item_id)\n",
    "            ratings['rating'] = prediction\n",
    "            \n",
    "            ratings_list.append(ratings)\n",
    "            \n",
    "            ratings = {}\n",
    "            \n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  10.704530599999998\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "predicted_scores_dict =  predict_scores_df(data, df_final)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Dataframe with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediced_scores_dict = predict_scores_df(data, df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586121</td>\n",
       "      <td>942</td>\n",
       "      <td>1677</td>\n",
       "      <td>3.8956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586122</td>\n",
       "      <td>942</td>\n",
       "      <td>1678</td>\n",
       "      <td>3.82475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586123</td>\n",
       "      <td>942</td>\n",
       "      <td>1679</td>\n",
       "      <td>3.93498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586124</td>\n",
       "      <td>942</td>\n",
       "      <td>1680</td>\n",
       "      <td>3.85935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586125</td>\n",
       "      <td>942</td>\n",
       "      <td>1681</td>\n",
       "      <td>3.94136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686126 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID movieID   rating   timestamp\n",
       "0          196     242        3   881250949\n",
       "1          186     302        3   891717742\n",
       "2           22     377        1   878887116\n",
       "3          244      51        2   880606923\n",
       "4          166     346        1   886397596\n",
       "...        ...     ...      ...         ...\n",
       "1586121    942    1677   3.8956         NaN\n",
       "1586122    942    1678  3.82475         NaN\n",
       "1586123    942    1679  3.93498         NaN\n",
       "1586124    942    1680  3.85935         NaN\n",
       "1586125    942    1681  3.94136         NaN\n",
       "\n",
       "[1686126 rows x 4 columns]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_all_users = df_final.append(predicted_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data(data):\n",
    "#     trainset = data.build_full_trainset()\n",
    "    \n",
    "#     user_ids = trainset.all_users()\n",
    "    \n",
    "#     data_list = []\n",
    "#     for user_id in user_ids:\n",
    "#         for movie in range(item_ids[-1]+1, item_ids[-1]*100):\n",
    "\n",
    "#             new_data = {}\n",
    "\n",
    "#             new_data['userID'] = str(user_id)\n",
    "#             new_data['movieID'] = str(movie)\n",
    "#             new_data['rating'] = random.randint(1,5)\n",
    "\n",
    "#             data_list.append(new_data)\n",
    "#     return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data_other(data):\n",
    "#     trainset = data.build_full_trainset()\n",
    "\n",
    "#     user_ids = trainset.all_users()\n",
    "#     item_ids = trainset.all_items()\n",
    "\n",
    "#     data_list = []\n",
    "#     for user_id in user_ids:\n",
    "#         for movie in range(item_ids[-1]+1, item_ids[-1]*60):\n",
    "\n",
    "#             new_data = str(user_id)+'\\t'+str(movie)+'\\t'+str(random.randint(1,5))+'\\t'+'NaN\\n'\n",
    "\n",
    "#             data_list.append(new_data)\n",
    "#     return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_other(data):\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    data_list = []\n",
    "    # Create new movies (168200 in total)\n",
    "    for movie in range(item_ids[-1]+1, item_ids[-1]*100):\n",
    "        # For every movie, there will be 100 users rating the movie\n",
    "        user_generated = [randint(0, user_ids[-1]) for p in range(0, 100)]\n",
    "        for user in user_generated:\n",
    "            # Create a random generated score for the movies\n",
    "            new_data = str(user)+'\\t'+str(movie)+'\\t'+str(random.randint(1,5))+'\\t'+'NaN\\n'\n",
    "\n",
    "            data_list.append(new_data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_newest = create_data_other(data_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new data (as a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "new_data.extend(all_lines)\n",
    "new_data.extend(data_newest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check difference in sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.418"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_newest)/len(all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file on filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data into an array of strings\n",
    "with open('./new_data.data') as f:\n",
    "    all_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data to be used in Surprise\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file('./new_data.data', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "ratings = predict_scores(data)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
