{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "import zipfile\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise import accuracy\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data into an array of strings\n",
    "with open('./ml-100k/u.data') as f:\n",
    "    all_lines = f.readlines()\n",
    "\n",
    "# Prepare the data to be used in Surprise\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file('./new_data.data', reader=reader)\n",
    "\n",
    "\n",
    "# reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "# data = Dataset.load_from_file('./ml-100k/u.data', reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_content(data):\n",
    "    return r_unwanted.sub(\", \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    df_data = pd.DataFrame(data)\n",
    "\n",
    "    df_data[0] = df_data[0].apply(strip_content)\n",
    "\n",
    "    foo = lambda x: pd.Series([i for i in (x.split(','))])\n",
    "\n",
    "    df_final = df_data[0].apply(foo)\n",
    "\n",
    "    df_final.rename(columns={0:'userID', 1:'movieID', 2:'rating', 3: 'timestamp'}, \n",
    "                     inplace=True)\n",
    "\n",
    "    df_final = df_final.drop(columns=[4])\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = create_dataframe(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\"],\n",
    "#     \"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [False, True],\n",
    "# }\n",
    "\n",
    "# param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "# gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Grid search for best params </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"n_epochs\": [5, 10],\n",
    "#     \"lr_all\": [0.002, 0.005],\n",
    "#     \"reg_all\": [0.4, 0.6]\n",
    "# }\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "# gs.fit(data)\n",
    "\n",
    "# print(gs.best_score[\"rmse\"])\n",
    "# print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> SVD algo chosen, with best params obtained from GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(algo, data_other, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create train and test set, apply predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_predict_train_test(data):\n",
    "    # sample random trainset and testset\n",
    "    # test set is made of 25% of the ratings.\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "    # We'll use the famous SVD algorithm.\n",
    "    algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)\n",
    "\n",
    "    # Train the algorithm on the trainset, and predict ratings for the testset\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    return accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING ALGO\n",
      "\n",
      "CALCULATING RMSE USING A TEST SET (1/4) OF TRAINING SET\n",
      "RMSE: 1.4184\n",
      "Time to calculate RMSE:  974.1952820000001 \n",
      "\n",
      "BUILDING TRAINING SET\n",
      "\n",
      "TRAINING ALGORITHM\n",
      "Time to train alogrithm  1022.7955871000001 \n",
      "\n",
      "PREDICTING RATINGS\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.79   {'was_impossible': False}\n",
      "Time to train alogrithm  4886.2979094 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CREATING ALGO\\n\")\n",
    "algo = SVD(n_epochs=10, lr_all=0.005, reg_all=0.4)\n",
    "\n",
    "print(\"CALCULATING RMSE USING A TEST SET (1/4) OF TRAINING SET\")\n",
    "start = timeit.default_timer()\n",
    "rmse = RMSE_predict_train_test(data)\n",
    "stop = timeit.default_timer()\n",
    "print('Time to calculate RMSE: ', stop - start, \"\\n\")  \n",
    "\n",
    "print(\"BUILDING TRAINING SET\\n\")\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "print(\"TRAINING ALGORITHM\")\n",
    "start = timeit.default_timer()\n",
    "algo.fit(trainset)\n",
    "stop = timeit.default_timer()\n",
    "print('Time to train alogrithm ', stop - start, \"\\n\") \n",
    "\n",
    "\n",
    "print(\"PREDICTING RATINGS\")\n",
    "start = timeit.default_timer()\n",
    "\n",
    "ratings = predict_scores(data, algo)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time to train alogrithm ', stop - start, \"\\n\") \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158685456"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Training Time\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_time(data):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    algo.fit(trainset)\n",
    "\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  5.9843355\n"
     ]
    }
   ],
   "source": [
    "training_time(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Predict scores for all users for all movies. Test the speed of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores(data, algo):\n",
    "        # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    # Create empty list to store predictions\n",
    "    ratings = []\n",
    "    \n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings.append(prediction)\n",
    "            \n",
    "    print(algo.predict(str(196), str(302), 4))\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Time to predict all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.02   {'was_impossible': False}\n",
      "Time:  21.4044990000001\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "ratings = predict_scores(data, algo)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores_df(data, df):\n",
    "    # Build Training set. Needed to fit to create model.\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Get all the user and item IDs\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    # Create empty list to store predictions\n",
    "    ratings = {}\n",
    "    ratings_list = []\n",
    "    # For loop, estimate rating of each user for every movie.\n",
    "    for user_id in user_ids:\n",
    "        for item_id in item_ids:\n",
    "            \n",
    "            prediction = algo.predict(str(user_id), str(item_id)).est\n",
    "#             print(prediction)\n",
    "            ratings['userID'] = str(user_id)\n",
    "            ratings['movieID'] = str(item_id)\n",
    "            ratings['rating'] = prediction\n",
    "            \n",
    "            ratings_list.append(ratings)\n",
    "            \n",
    "            ratings = {}\n",
    "            \n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "predicted_scores_dict =  predict_scores_df(data, df_final)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Dataframe with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediced_scores_dict = predict_scores_df(data, df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ratings_all_users = df_final.append(predicted_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data(data):\n",
    "#     trainset = data.build_full_trainset()\n",
    "    \n",
    "#     user_ids = trainset.all_users()\n",
    "    \n",
    "#     data_list = []\n",
    "#     for user_id in user_ids:\n",
    "#         for movie in range(item_ids[-1]+1, item_ids[-1]*100):\n",
    "\n",
    "#             new_data = {}\n",
    "\n",
    "#             new_data['userID'] = str(user_id)\n",
    "#             new_data['movieID'] = str(movie)\n",
    "#             new_data['rating'] = random.randint(1,5)\n",
    "\n",
    "#             data_list.append(new_data)\n",
    "#     return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data_other(data):\n",
    "#     trainset = data.build_full_trainset()\n",
    "\n",
    "#     user_ids = trainset.all_users()\n",
    "#     item_ids = trainset.all_items()\n",
    "\n",
    "#     data_list = []\n",
    "#     for user_id in user_ids:\n",
    "#         for movie in range(item_ids[-1]+1, item_ids[-1]*60):\n",
    "\n",
    "#             new_data = str(user_id)+'\\t'+str(movie)+'\\t'+str(random.randint(1,5))+'\\t'+'NaN\\n'\n",
    "\n",
    "#             data_list.append(new_data)\n",
    "#     return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_other(data):\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    user_ids = trainset.all_users()\n",
    "    item_ids = trainset.all_items()\n",
    "\n",
    "    data_list = []\n",
    "    # Create new movies (168200 in total)\n",
    "    for movie in range(item_ids[-1]+1, item_ids[-1]*100):\n",
    "        # For every movie, there will be 100 users rating the movie\n",
    "        user_generated = [randint(0, user_ids[-1]) for p in range(0, 100)]\n",
    "        for user in user_generated:\n",
    "            # Create a random generated score for the movies\n",
    "            new_data = str(user)+'\\t'+str(movie)+'\\t'+str(random.randint(1,5))+'\\t'+'NaN\\n'\n",
    "\n",
    "            data_list.append(new_data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_newest = create_data_other(data_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new data (as a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "new_data.extend(all_lines)\n",
    "new_data.extend(data_newest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check difference in sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_newest)/len(all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file on filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data into an array of strings\n",
    "with open('./new_data.data') as f:\n",
    "    all_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data to be used in Surprise\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file('./new_data.data', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "ratings = predict_scores(data)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
